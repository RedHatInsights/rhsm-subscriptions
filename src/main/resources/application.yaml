# These are core, default properties that we don't want the user to change.  Take care to use
# spring.config.additional-location instead of spring.config.location so that this file will continue
# getting loaded.
# See https://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-external-config.html#boot-features-external-config-application-property-files

spring:
  # load the common core definitions
  config:
    import: classpath:swatch-core/application.yaml
  profiles:
    active:
      - api
      - capacity-ingress
      - rhsm-conduit
      - worker
      - openshift-metering-worker
      - rh-marketplace
      - kafka-queue
  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_HOST}:${KAFKA_BOOTSTRAP_PORT}
    listener:
      # The number of threads that will be processing messages (should match
      # the number of partitions on the queue)
      concurrency: ${KAFKA_MESSAGE_THREADS:1}
      idle-event-interval: ${KAFKA_IDLE_EVENT_INTERVAL:5s}
    consumer:
      properties:
        # Required kafka defaults
        max.poll.interval.ms: ${KAFKA_CONSUMER_MAX_POLL_INTERVAL_MS:1800000}
        reconnect.backoff.ms: ${KAFKA_CONSUMER_RECONNECT_BACKOFF_MS:2000}
        reconnect.backoff.max.ms: ${KAFKA_CONSUMER_RECONNECT_BACKOFF_MAX_MS:10000}
        default.api.timeout.ms: ${KAFKA_API_RECONNECT_TIMEOUT_MS:480000}
      # if no offset commit exists yet, set to earliest
      auto-offset-reset: earliest
      max-poll-records: 1
  jms:
    listener:
      auto-startup: ${UMB_ENABLED:false}

rhsm-subscriptions:
  jobs:
    purge-snapshot-schedule: ${PURGE_SNAPSHOT-SCHEDULE:0 0 1 * * ?}
    purge-events-schedule: ${PURGE_EVENTS_SCHEDULE:0 0 1 * * ?}
  account-batch-size: ${ACCOUNT_BATCH_SIZE:1}
  product-denylist-resource-location: ${PRODUCT_DENYLIST_RESOURCE_LOCATION:}
  metering:
    prometheus:
      client:
        token: ${PROM_AUTH_TOKEN:}
        url: ${PROM_URL:https://localhost/api/v1}
      metric:
        accountQueryTemplates:
          default: >-
            ${OPENSHIFT_ENABLED_ACCOUNT_PROMQL:group(min_over_time(#{metric.prometheus.queryParams[metadataMetric]}{product='#{metric.prometheus.queryParams[product]}', external_organization != '', billing_model='marketplace'}[1h]))
            by (external_organization)}
          addonSamples: >-
            ${OPENSHIFT_ENABLED_ACCOUNT_PROMQL:group(min_over_time(#{metric.prometheus.queryParams[metadataMetric]}{resource_type="addon", resource_name='#{metric.prometheus.queryParams[resourceName]}', external_organization != '', billing_model='marketplace'}[1h]))
            by (external_organization)}
  prometheus-latency-duration: ${PROMETHEUS_LATENCY_DURATION:0h}
  hourly-tally-offset: ${HOURLY_TALLY_OFFSET:60m}
  metric-lookup-range-duration: ${METRIC_LOOKUP_RANGE:1h}
  subscription-sync-enabled: ${SUBSCRIPTION_SYNC_ENABLED:false}
  enable-synchronous-operations: ${ENABLE_SYNCHRONOUS_OPERATIONS:false}
  subscription:
    use-stub: ${SUBSCRIPTION_USE_STUB:false}
    url: ${SUBSCRIPTION_URL:https://subscription.stage.api.redhat.com/svcrest/subscription/v5}
    keystore: file:${SUBSCRIPTION_KEYSTORE:}
    keystore-password: ${SUBSCRIPTION_KEYSTORE_PASSWORD:changeit}
    max-connections: ${SUBSCRIPTION_MAX_CONNECTIONS:100}
    max-retry-attempts: ${SUBSCRIPTION_MAX_RETRY_ATTEMPTS:4}
    back-off-max-interval: ${SUBSCRIPTION_BACK_OFF_MAX_INTERVAL:64s}
    back-off-initial-interval: ${SUBSCRIPTION_BACK_OFF_INITIAL_INTERVAL:1s}
    back-off-multiplier: ${SUBSCRIPTION_BACK_OFF_MULTIPLIER:2}
    page-size: ${SUBSCRIPTION_PAGE_SIZE:1000}
    ignore-expired-older-than: ${SUBSCRIPTION_IGNORE_EXPIRED_OLDER_THAN:2m}
    ignore-starting-later-than: ${SUBSCRIPTION_IGNORE_STARTING_LATER_THAN:2m}
    enable-payg-subscription-force-sync: ${ENABLE_PAYG_SUBSCRIPTION_FORCE_SYNC:false}
  user-service:
    use-stub: ${USER_USE_STUB:false}
    url: https://${USER_HOST:localhost}:${USER_PORT:443}
    max-connections: ${USER_MAX_CONNECTIONS:100}
    keystore: file:${RHSM_KEYSTORE:}
    keystore-password: ${RHSM_KEYSTORE_PASSWORD:changeit}
    back-off-initial-interval: ${USER_BACK_OFF_INITIAL_INTERVAL:1s}
    back-off-max-interval: ${USER_BACK_OFF_MAX_INTERVAL:1m}
    back-off-multiplier: ${USER_BACK_OFF_MULTIPLIER:2}
    max-attempts: ${USER_MAX_ATTEMPTS:1}
management:
  health:
    jms:
      # disable activemq health checks when we're not actually using UMB
      enabled: ${UMB_ENABLED:false}

#Current version of spring-kafka(3.0.10) has bug that logs incorrect warning: https://github.com/spring-projects/spring-kafka/issues/2784
#TODO remove this. Fixed in next release
logging:
  level:
    org:
      springframework:
        kafka:
          listener:
            DeadLetterPublishingRecoverer=error: