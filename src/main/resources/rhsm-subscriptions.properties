# Place application related defaults here.  This file is loaded via the @PropertySource annotation on the
# ApplicationConfiguration class.  Prefix properties in this file appropriately (e.g. "subscriptions") so the
# classes annotated with @ConfigurationProperties will ingest them.

# We're keeping the context-path as "/" so that the actuators we use for OKD liveness/readiness probes have a
# fixed path.  The actual subscriptions resources will be configured to hang off of the path below.

spring.jmx.enabled=${JMX_ENABLED:true}

# General hibernate configurations
spring.jpa.properties.hibernate.jdbc.batch_size=${JDBC_BATCH_SIZE:100}
spring.jpa.properties.hibernate.order_inserts=true
spring.jpa.properties.hibernate.order_updates=true

rhsm-subscriptions.dev-mode=${DEV_MODE:false}
rhsm-subscriptions.prettyPrintJson=${PRETTY_PRINT_JSON:false}
rhsm-subscriptions.package_uri_mappings.org.candlepin.subscriptions=${PATH_PREFIX:api}/${APP_NAME:rhsm-subscriptions}/v1

rhsm-subscriptions.inventory-service.datasource.url=jdbc:postgresql://${INVENTORY_DATABASE_HOST:localhost}/${INVENTORY_DATABASE_DATABASE:inventory}
rhsm-subscriptions.inventory-service.datasource.username=${INVENTORY_DATABASE_USERNAME:insights}
rhsm-subscriptions.inventory-service.datasource.password=${INVENTORY_DATABASE_PASSWORD:insights}
rhsm-subscriptions.inventory-service.datasource.driver-class-name=org.postgresql.Driver
rhsm-subscriptions.inventory-service.datasource.platform=postgresql

# Use Spring Resource notation for this (e.g. "classpath:" or "file:")
rhsm-subscriptions.product_id_to_products_map_resource_location=classpath:product_id_to_products_map.yaml
rhsm-subscriptions.role_to_products_map_resource_location=classpath:role_to_products_map.yaml
rhsm-subscriptions.arch_to_product_map_resource_location=classpath:arch_to_product_map.yaml
rhsm-subscriptions.product_whitelist_resource_location=${PRODUCT_WHITELIST_RESOURCE_LOCATION:}
rhsm-subscriptions.account_list_resource_location=${ACCOUNT_LIST_RESOURCE_LOCATION:}

rhsm-subscriptions.datasource.url=jdbc:postgresql://${DATABASE_HOST:localhost}:${DATABASE_PORT:5432}/${DATABASE_DATABASE:rhsm-subscriptions}?reWriteBatchedInserts=true
rhsm-subscriptions.datasource.username=${DATABASE_USERNAME:rhsm-subscriptions}
rhsm-subscriptions.datasource.password=${DATABASE_PASSWORD:rhsm-subscriptions}
rhsm-subscriptions.datasource.driver-class-name=org.postgresql.Driver
rhsm-subscriptions.datasource.platform=postgresql

# Capture snapshot schedule
rhsm-subscriptions.jobs.captureSnapshotSchedule=${CAPTURE_SNAPSHOT_SCHEDULE:0 0/5 * * * ?}
rhsm-subscriptions.account-batch-size=${ACCOUNT_BATCH_SIZE:1}

# Tally retention policy
rhsm-subscriptions.tally-retention-policy.daily=${TALLY_RETENTION_DAILY:37}
rhsm-subscriptions.tally-retention-policy.weekly=${TALLY_RETENTION_WEEKLY:12}
rhsm-subscriptions.tally-retention-policy.monthly=${TALLY_RETENTION_MONTHLY:12}
rhsm-subscriptions.tally-retention-policy.quarterly=${TALLY_RETENTION_QUARTERLY:16}
rhsm-subscriptions.tally-retention-policy.yearly=${TALLY_RETENTION_YEARLY:5}

##########################
# kafka configuration
##########################

# Use profile "kafka-queue" to enable Kafka integration
# Use profile "worker" to enable Kafka listeners
rhsm-subscriptions.tasks.task-group=${KAFKA_TASK_GROUP:platform.rhsm-subscriptions.tasks}

# if no offset commit exists yet, set to earliest
spring.kafka.consumer.properties.auto.offset.reset=earliest

# Required kafka defaults
spring.kafka.consumer.properties.max.poll.records=1
spring.kafka.consumer.properties.max.poll.interval.ms=${KAFKA_CONSUMER_MAX_POLL_INTERVAL_MS:1800000}

# The number of threads that will be processing messages (should match
# the number of partitions on the queue)
spring.kafka.listener.concurrency=${KAFKA_MESSAGE_THREADS:1}
spring.kafka.bootstrap-servers=${KAFKA_BOOTSTRAP_HOST:localhost}:${KAFKA_BOOTSTRAP_PORT:9092}
spring.kafka.consumer.properties.reconnect.backoff.ms=${KAFKA_CONSUMER_RECONNECT_BACKOFF_MS:2000}
spring.kafka.consumer.properties.reconnect.backoff.max.ms=${KAFKA_CONSUMER_RECONNECT_BACKOFF_MAX_MS:10000}
spring.kafka.consumer.properties.default.api.timeout.ms=${KAFKA_API_RECONNECT_TIMEOUT_MS:480000}

###################################
# RBAC Configuration
###################################
rhsm-subscriptions.rbacApplicationName=${RBAC_APPLICATION_NAME:subscriptions}
rhsm-subscriptions.rbac-service.useStub=${RBAC_USE_STUB:false}
rhsm-subscriptions.rbac-service.url=http://${RBAC_HOST:localhost}:${RBAC_PORT:8819}/api/rbac/v1
rhsm-subscriptions.rbac-service.maxConnections=${RBAC_MAX_CONNECTIONS:100}

###################################
# Hawtio Console Configuration
###################################
# Base path override for reverse proxy support
rhsm-subscriptions.hawtioBasePath=${HAWTIO_BASE_PATH:}
# See https://hawt.io/docs/configuration/ for details on built-in hawtio config
hawtio.authenticationEnabled=${HAWTIO_AUTHENTICATION_ENABLED:false}
# disable the remote connection tab, we do not need it
hawtio.disableProxy=${HAWTIO_DISABLE_PROXY:true}
hawtio.proxyAllowlist=${HAWTIO_PROXY_ALLOWLIST:localhost,127.0.0.1}
hawtio.localAddressProbing=${HAWTIO_LOCAL_ADDRESS_PROBING:true}

###################################
# cloudigrade Configuration
###################################
rhsm-subscriptions.cloudigrade-enabled=${CLOUDIGRADE_ENABLED:false}
rhsm-subscriptions.cloudigrade-max-attempts=${CLOUDIGRADE_MAX_ATTEMPTS:2}
rhsm-subscriptions.cloudigrade.url=http://${CLOUDIGRADE_HOST:localhost}:${CLOUDIGRADE_PORT:8080}/api/cloudigrade/v2
rhsm-subscriptions.cloudigrade.maxConnections=${CLOUDIGRADE_MAX_CONNECTIONS:100}

###################################
# rhsm-conduit Configuration
###################################
# The cron schedule is only used in development mode.  In a production deployment, a version of the
# application with the "orgsync" profile is deployed and run as a one-shot job.  The scheduling
# is handled by OpenShift's cron capabilities.
rhsm-conduit.org-sync.schedule=${ORG_SYNC_SCHEDULE:0 */2 * * * ?}
rhsm-conduit.org-sync.strategy = ${ORG_SYNC_STRATEGY:fileBasedOrgListStrategy}

# Use Spring Resource notation for this (e.g. "classpath:" or "file:")
rhsm-conduit.org-sync.fileBasedOrgListStrategy.org-resource-location=${ORG_SYNC_RESOURCE_LOCATION:classpath:empty-org-list.txt}

# Pinhead service default properties
rhsm-conduit.pinhead.useStub=${PINHEAD_USE_STUB:false}
rhsm-conduit.pinhead.url=${PINHEAD_URL:http://localhost:9090}
rhsm-conduit.pinhead.keystore_file=${PINHEAD_KEYSTORE:}
rhsm-conduit.pinhead.keystore_password=${PINHEAD_KEYSTORE_PASSWORD:changeit}
rhsm-conduit.pinhead.requestBatchSize=${PINHEAD_BATCH_SIZE:1000}
rhsm-conduit.pinhead.maxConnections=${PINHEAD_MAX_CONNECTIONS:100}

# The API key configured by the inventory service.
rhsm-conduit.inventory-service.useStub=${INVENTORY_USE_STUB:true}
rhsm-conduit.inventory-service.apiKey=${INVENTORY_API_KEY:changeit}
rhsm-conduit.inventory-service.host-last-sync-threshold=${INVENTORY_HOST_LAST_SYNC_THRESHOLD:24h}
rhsm-conduit.inventory-service.add-uuid-hyphens=${INVENTORY_ADD_UUID_HYPHENS:false}
# FIXME: misnamed, it's actually in hours
rhsm-conduit.inventory-service.staleHostOffsetInDays=${INVENTORY_STALE_HOST_OFFSET_HOURS:48}

# Inventory service kafka configuration
rhsm-conduit.inventory-service.enableKafka=${INVENTORY_ENABLE_KAFKA:true}
rhsm-conduit.inventory-service.kafkaHostIngressTopic=${INVENTORY_HOST_INGRESS_TOPIC:platform.inventory.host-ingress}
