SERVER_PORT=${clowder.endpoints.swatch-metrics.port:8000}
LOGGING_LEVEL_COM_REDHAT_SWATCH=INFO
LOGGING_LEVEL_ROOT=INFO
CORS_ORIGINS=/.+\\.redhat\\.com/
DISABLE_OTEL=true
%ephemeral.DISABLE_OTEL=true

ENABLE_SPLUNK_HEC=true
SPLUNK_HEC_URL=https://splunk-hec.redhat.com:8088/
SPLUNK_SOURCE=swatch-metrics
SPLUNK_SOURCE_TYPE=quarkus_service
SPLUNK_HEC_BATCH_SIZE=1000
SPLUNK_HEC_BATCH_INTERVAL=10S
SPLUNK_HEC_RETRY_COUNT=3
SPLUNK_HEC_INCLUDE_EX=false

METRICS_IN_FAIL_ON_DESER_FAILURE=true
METERING_TASK_TOPIC=platform.rhsm-subscriptions.metering-tasks
SERVICE_INSTANCE_INGRESS_TOPIC=platform.rhsm-subscriptions.service-instance-ingress

# dev-specific defaults; these can still be overridden by env var
%dev.SERVER_PORT=8016
%dev.QUARKUS_MANAGEMENT_PORT=9016
%dev.LOGGING_LEVEL_COM_REDHAT_SWATCH=DEBUG
%dev.SWATCH_SELF_PSK=placeholder
%dev.ENABLE_SPLUNK_HEC=false
%dev.SPLUNK_HEC_URL=https://splunk-hec.prod.utility-us-east-2.redhat.com:8088/
%dev.HOST_NAME=${USER}@${HOSTNAME}
%dev.SPLUNKMETA_namespace=local
%dev.SPLUNK_HEC_INCLUDE_EX=true
%dev.SPLUNK_DISABLE_CERTIFICATE_VALIDATION=true
%dev.CORS_ORIGINS=/.*/
%dev.PROM_URL=http://localhost:9090/api/v1

# set the test profile properties to the same values as dev; these get activated for @QuarkusTest
%test.SWATCH_SELF_PSK=${%dev.SWATCH_SELF_PSK}
%test.ENABLE_SPLUNK_HEC=${%dev.ENABLE_SPLUNK_HEC}
%test.HOST_NAME=unit_tests

# dev-specific config items that don't need to be overridden via env var
# do not use JSON logs in dev mode
%dev.quarkus.log.console.json=false
quarkus.log.level=${LOGGING_LEVEL_ROOT}
# customized w/ %X which shows MDC values
quarkus.log.console.format=%d{yyyy-MM-dd HH:mm:ss,SSS} %-5p [%c{3.}] (%t) %X %s%e%n
quarkus.log.category."com.redhat.swatch".level=${LOGGING_LEVEL_COM_REDHAT_SWATCH}

quarkus.http.port=${SERVER_PORT}
quarkus.http.test-port=0
quarkus.http.cors.enabled=true
quarkus.http.cors.origins=${CORS_ORIGINS}
# Exposing the health checks and metrics on :9000.
quarkus.management.enabled=true
# But disable during testing to prevent port conflict during parallel runs
%test.quarkus.management.enabled=false
quarkus.management.port=9000
# Configure the Quarkus non application paths to listen on "/" instead of "/q"
quarkus.management.root-path=/

quarkus.log.handler.splunk.enabled=${ENABLE_SPLUNK_HEC:false}
quarkus.log.handler.splunk.url=${SPLUNK_HEC_URL:https://splunk-hec.redhat.com:8088/}
quarkus.log.handler.splunk.disable-certificate-validation=${SPLUNK_DISABLE_CERTIFICATE_VALIDATION:false}
quarkus.log.handler.splunk.token=${SPLUNK_HEC_TOKEN:replaceme}
quarkus.log.handler.splunk.metadata-source=${SPLUNK_SOURCE:swatch-metrics}
quarkus.log.handler.splunk.metadata-source-type=${SPLUNK_SOURCE_TYPE:quarkus_service}
quarkus.log.handler.splunk.metadata-host=${HOST_NAME:${USER}@${HOSTNAME}}
quarkus.log.handler.splunk.batch-size-count=${SPLUNK_HEC_BATCH_SIZE:1000}
quarkus.log.handler.splunk.batch-interval=${SPLUNK_HEC_BATCH_INTERVAL:10S}
quarkus.log.handler.splunk.max-retries=${SPLUNK_HEC_RETRY_COUNT:0}
quarkus.log.handler.splunk.metadata-fields.namespace=${SPLUNKMETA_namespace:local}
quarkus.log.handler.splunk.format=%d %-5p [%c{3.}] (%t) %s%e%n
quarkus.log.handler.splunk.include-exception=${SPLUNK_HEC_INCLUDE_EX:false}

# Everything on the main Splunk handler needs to be duplicated here.  The only difference is the
# source-type, the format (which we don't want to mess with), and the include-exception (which
# is not germane).  It's tedious but the configuration from the root handler *is not* inherited
quarkus.log.handler.splunk."ACCESS_LOG".enabled=${ENABLE_SPLUNK_HEC:false}
quarkus.log.handler.splunk."ACCESS_LOG".url=${SPLUNK_HEC_URL:https://splunk-hec.redhat.com:8088/}
quarkus.log.handler.splunk."ACCESS_LOG".disable-certificate-validation=${SPLUNK_DISABLE_CERTIFICATE_VALIDATION:false}
quarkus.log.handler.splunk."ACCESS_LOG".token=${SPLUNK_HEC_TOKEN:replaceme}
quarkus.log.handler.splunk."ACCESS_LOG".metadata-source=${SPLUNK_SOURCE:swatch-metrics}
quarkus.log.handler.splunk."ACCESS_LOG".metadata-source-type=access_combined
quarkus.log.handler.splunk."ACCESS_LOG".metadata-host=${HOST_NAME:${USER}@${HOSTNAME}}
quarkus.log.handler.splunk."ACCESS_LOG".batch-size-count=${SPLUNK_HEC_BATCH_SIZE:1000}
quarkus.log.handler.splunk."ACCESS_LOG".batch-interval=${SPLUNK_HEC_BATCH_INTERVAL:10S}
quarkus.log.handler.splunk."ACCESS_LOG".max-retries=${SPLUNK_HEC_RETRY_COUNT:0}
quarkus.log.handler.splunk."ACCESS_LOG".metadata-fields.namespace=${SPLUNKMETA_namespace:local}

quarkus.http.access-log.enabled=true
quarkus.http.access-log.pattern=combined

quarkus.log.category."io.quarkus.http.access-log".handlers=ACCESS_LOG
# Don't send access log messages to the root handler
quarkus.log.category."io.quarkus.http.access-log".use-parent-handlers=false
quarkus.log.category."org.jboss.resteasy.reactive.common.core.AbstractResteasyReactiveContext".level=DEBUG

# rest-client debug logging
# NOTE: all of uri-filter-regex, log category level, and logging.scope need to be set for a request/response to be logged.
quarkus.log.category."com.redhat.swatch.resteasy.client.DebugClientLogger".level=DEBUG
%test.quarkus.rest-client.logging.scope=request-response
%dev.quarkus.rest-client.logging.scope=request-response
%ephemeral.quarkus.rest-client.logging.scope=request-response

quarkus.rest-client."com.redhat.swatch.clients.prometheus.api.resources.QueryApi".url=${rhsm-subscriptions.metering.prometheus.client.url}
quarkus.rest-client."com.redhat.swatch.clients.prometheus.api.resources.QueryApi".scope=jakarta.enterprise.context.ApplicationScoped
quarkus.rest-client."com.redhat.swatch.clients.prometheus.api.resources.QueryApi".providers=com.redhat.swatch.resteasy.client.DebugClientLogger
quarkus.rest-client."com.redhat.swatch.clients.prometheus.api.resources.QueryRangeApi".url=${rhsm-subscriptions.metering.prometheus.client.url}
quarkus.rest-client."com.redhat.swatch.clients.prometheus.api.resources.QueryRangeApi".scope=jakarta.enterprise.context.ApplicationScoped
quarkus.rest-client."com.redhat.swatch.clients.prometheus.api.resources.QueryRangeApi".providers=com.redhat.swatch.resteasy.client.DebugClientLogger

# Kafka security configuration.  These properties must be present so that
# clowder-quarkus-config-source will populate them from the Clowder provided configuration JSON.
# If the properties are simply absent from this file, then clowder-quarkus-config-source will not
# set values for the property even if a value is present in the Clowder JSON.  The exception is the
# kafka.ssl.truststore.location which needs to evaluate to null for Kafka to use the system
# truststore.  Only specify kafka.ssl.truststore.location when you have an actual location to
# point to.  Don't set it to empty string.
#
# Additionally, Kafka has a bug, https://issues.apache.org/jira/browse/KAFKA-4090, where if a
# client attempts to connect to a TLS enabled port using PLAINTEXT, an OutOfMemoryException gets
# thrown instead of something more relevant to the actual issue.
kafka.sasl.jaas.config = ""
kafka.sasl.mechanism = PLAIN
kafka.security.protocol = PLAINTEXT
#kafka.ssl.truststore.location = ""
#kafka.ssl.truststore.type = PEM

quarkus.kafka.devservices.enabled=false
# Clowder quarkus config takes care of setting the common kafka settings
kafka.bootstrap.servers=localhost:9092

mp.messaging.incoming.tasks-in.connector=smallrye-kafka
mp.messaging.incoming.tasks-in.topic=${METERING_TASK_TOPIC}
mp.messaging.incoming.tasks-in.value.deserializer=com.redhat.swatch.metrics.service.json.MetricsTaskDescriptorDeserializer
mp.messaging.incoming.tasks-in.fail-on-deserialization-failure=${METRICS_IN_FAIL_ON_DESER_FAILURE}
mp.messaging.incoming.tasks-in.auto.offset.reset=earliest
# This value needs to be synced with the retry configuration which will retry up to
# 3 times with a max duration of 120 seconds, so the correct value would be 3 x 120
mp.messaging.incoming.tasks-in.throttled.unprocessed-record-max-age.ms=360000

mp.messaging.outgoing.tasks-out.connector=smallrye-kafka
mp.messaging.outgoing.tasks-out.topic=${METERING_TASK_TOPIC}
mp.messaging.outgoing.tasks-out.value.serializer=io.quarkus.kafka.client.serialization.ObjectMapperSerializer

mp.messaging.outgoing.events-out.connector=smallrye-kafka
mp.messaging.outgoing.events-out.topic=${SERVICE_INSTANCE_INGRESS_TOPIC}
# Workaround for https://github.com/smallrye/smallrye-reactive-messaging/issues/2465
# where 128 is the current default value for the buffer size
mp.messaging.outgoing.events-out.max-inflight-messages=128
mp.messaging.outgoing.events-out.value.serializer=io.quarkus.kafka.client.serialization.ObjectMapperSerializer

# otel config
quarkus.otel.sdk.disabled=${DISABLE_OTEL}
quarkus.otel.exporter.otlp.endpoint=${OTEL_EXPORTER_OTLP_ENDPOINT:http://splunk-otel-collector:4317}
# Metrics and logging are not yet supported - 30 Jul 2024
quarkus.otel.exporter.otlp.traces.protocol=${OTEL_EXPORTER_OTLP_PROTOCOL:grpc}

# expose swagger-ui and openapi JSON/YAML on turnpike-friendly paths
quarkus.smallrye-openapi.path=/api/${quarkus.application.name}/internal/openapi
# By default, the openapi and swagger ui endpoints are exposed on the management port, so we need to disable it
# to expose it on the server port 8000:
quarkus.smallrye-openapi.management.enabled=false
quarkus.swagger-ui.always-include=true
quarkus.swagger-ui.path=/api/${quarkus.application.name}/internal/swagger-ui

# Disable ALL dev services
quarkus.devservices.enabled=false

rhsm-subscriptions.prometheus-latency-duration=${PROMETHEUS_LATENCY_DURATION:0h}
rhsm-subscriptions.enable-synchronous-operations=${ENABLE_SYNCHRONOUS_OPERATIONS:false}
rhsm-subscriptions.metering.prometheus.client.token=${PROM_AUTH_TOKEN:}
rhsm-subscriptions.metering.prometheus.client.url=${PROM_URL:https://localhost/api/v1}
rhsm-subscriptions.metering.prometheus.metric.accountQueryTemplates.default=group(min_over_time(#{metric.prometheus.queryParams[metadataMetric]}{product='#{metric.prometheus.queryParams[product]}', external_organization != '', billing_model='marketplace'}[1h])) by (external_organization)
rhsm-subscriptions.metering.prometheus.metric.accountQueryTemplates.addonSamples=group(min_over_time(#{metric.prometheus.queryParams[metadataMetric]}{resource_type="addon", resource_name='#{metric.prometheus.queryParams[resourceName]}', external_organization != '', billing_model='marketplace'}[1h])) by (external_organization)
rhsm-subscriptions.metering.prometheus.metric.accountQueryTemplates.rhelemeter=group(min_over_time({product=~'#{metric.prometheus.queryParams[productLabelRegex]}', external_organization != '', billing_model='marketplace'}[1h])) by (external_organization)
# NB: This query does not use the billing_model label since ROSA Classic is "standard" and HCP is "marketplace"
rhsm-subscriptions.metering.prometheus.metric.accountQueryTemplates.rosa=group(min_over_time(#{metric.prometheus.queryParams[metadataMetric]}{product=~'#{metric.prometheus.queryParams[productLabelRegex]}', external_organization != ''}[1h])) by (external_organization)
rhsm-subscriptions.metering.prometheus.metric.queryTemplates.default=max(#{metric.prometheus.queryParams[metric]}) by (#{metric.prometheus.queryParams[instanceKey]}) * on(#{metric.prometheus.queryParams[instanceKey]}) group_right min_over_time(#{metric.prometheus.queryParams[metadataMetric]}{product="#{metric.prometheus.queryParams[product]}", external_organization="#{runtime[orgId]}", billing_model="marketplace", metered_by_rh!='false'}[1h])
rhsm-subscriptions.metering.prometheus.metric.queryTemplates.addonSamples=max(#{metric.prometheus.queryParams[metric]}) by (#{metric.prometheus.queryParams[instanceKey]}) * on(#{metric.prometheus.queryParams[instanceKey]}) group_right min_over_time(#{metric.prometheus.queryParams[metadataMetric]}{resource_type="addon",resource_name="#{metric.prometheus.queryParams[resourceName]}", external_organization="#{runtime[orgId]}", billing_model="marketplace", metered_by_rh!='false'}[1h])
rhsm-subscriptions.metering.prometheus.metric.queryTemplates.rhelemeter=sum_over_time((max by (#{metric.prometheus.queryParams[instanceKey]}) (#{metric.prometheus.queryParams[metric]}))[1h:10m]) / scalar(count_over_time(vector(1)[1h:10m])) * on (#{metric.prometheus.queryParams[instanceKey]}) group_right topk by (#{metric.prometheus.queryParams[instanceKey]}) (1, group without (swatch_placeholder_label) (min_over_time(#{metric.prometheus.queryParams[metric]}{product=~"#{metric.prometheus.queryParams[productLabelRegex]}", external_organization="#{runtime[orgId]}", billing_model="marketplace", metered_by_rh!='false'}[1h])))
# NB: This query does not use the billing_model label since ROSA Classic is "standard" and HCP is "marketplace"
rhsm-subscriptions.metering.prometheus.metric.queryTemplates.rosa=max(#{metric.prometheus.queryParams[metric]}) by (#{metric.prometheus.queryParams[instanceKey]}) * on(#{metric.prometheus.queryParams[instanceKey]}) group_right topk by (#{metric.prometheus.queryParams[instanceKey]}) (1, min_over_time(#{metric.prometheus.queryParams[metadataMetric]}{product=~"#{metric.prometheus.queryParams[productLabelRegex]}", external_organization="#{runtime[orgId]}", support=~"Premium|Standard|Self-Support|None", metered_by_rh!='false'}[1h]))
rhsm-subscriptions.metering.prometheus.metric.maxAttempts=${OPENSHIFT_MAX_ATTEMPTS:50}
rhsm-subscriptions.metering.prometheus.metric.backOffMaxInterval=${OPENSHIFT_BACK_OFF_MAX_INTERVAL:50000}
rhsm-subscriptions.metering.prometheus.metric.backOffInitialInterval=${OPENSHIFT_BACK_OFF_INITIAL_INTERVAL:1000}
rhsm-subscriptions.metering.prometheus.metric.backOffMultiplier=${OPENSHIFT_BACK_OFF_MULTIPLIER:1.5}
rhsm-subscriptions.metering.prometheus.metric.eventSource=${EVENT_SOURCE:prometheus}
rhsm-subscriptions.metering.prometheus.metric.rangeInMinutes=${OPENSHIFT_METERING_RANGE:60}
